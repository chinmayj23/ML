{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_remedial7_J079.ipynb",
      "provenance": [],
      "mount_file_id": "1tS6beat3gjl0WNIqFHU1gh3TUsVklWba",
      "authorship_tag": "ABX9TyOGQxpC5EwmJHbe2T/Ulr9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmayj23/ML/blob/master/ML_remedial7_J079.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzKS5QSivrW1"
      },
      "source": [
        "iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIDZ04SAujI9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.random.seed(27)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CId3JQN5u2sP"
      },
      "source": [
        "data=pd.read_csv(\"/content/drive/My Drive/irisdata.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1pPPGa1vHxe",
        "outputId": "8dd59bb7-dba5-49cc-c868-6a58710c064a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlHBnZQ3vXCW"
      },
      "source": [
        "x=data.drop(columns=['species'],axis=1)\n",
        "y=data['species']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZIh_7dhvpeC"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y.unique())\n",
        "y = le.transform(y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzifbosnvv_h"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCMcgpJmvyjP"
      },
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "obj1 = ensemble.AdaBoostClassifier()\n",
        "obj2 = ensemble.BaggingClassifier()\n",
        "obj3 = ensemble.GradientBoostingClassifier()\n",
        "obj4 = ensemble.RandomForestClassifier()\n",
        "estimators = [obj1, obj2, obj3, obj4]\n",
        "obj5 = ensemble.StackingClassifier(estimators=estimators)\n",
        "obj6 = ensemble.VotingClassifier(estimators=estimators)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfyeFDWtv1i1"
      },
      "source": [
        "def get_cv_scores(model):\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')\n",
        "    print('CV Mean: ', np.mean(scores))\n",
        "    print('STD: ', np.std(scores))\n",
        "    print('\\n')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJGGXg0Jv3-0",
        "outputId": "87bc95d2-0762-4070-f7d2-aed97c74fc31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "models = [obj1, obj2, obj3, obj4,obj5,obj6]\n",
        "for model in models:\n",
        "    print(model)\n",
        "    get_cv_scores(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=50, random_state=None)\n",
            "CV Mean:  0.9583333333333334\n",
            "STD:  0.011785113019775804\n",
            "\n",
            "\n",
            "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
            "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
            "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
            "                  warm_start=False)\n",
            "CV Mean:  0.9666666666666667\n",
            "STD:  0.023570226039551605\n",
            "\n",
            "\n",
            "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "CV Mean:  0.9583333333333334\n",
            "STD:  0.03118047822311617\n",
            "\n",
            "\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "CV Mean:  0.9666666666666667\n",
            "STD:  0.03118047822311616\n",
            "\n",
            "\n",
            "StackingClassifier(cv=None,\n",
            "                   estimators=[AdaBoostClassifier(algorithm='SAMME.R',\n",
            "                                                  base_estimator=None,\n",
            "                                                  learning_rate=1.0,\n",
            "                                                  n_estimators=50,\n",
            "                                                  random_state=None),\n",
            "                               BaggingClassifier(base_estimator=None,\n",
            "                                                 bootstrap=True,\n",
            "                                                 bootstrap_features=False,\n",
            "                                                 max_features=1.0,\n",
            "                                                 max_samples=1.0,\n",
            "                                                 n_estimators=10, n_jobs=None,\n",
            "                                                 oob_score=False,\n",
            "                                                 random_state=None, verbose=0,\n",
            "                                                 warm_start=False...\n",
            "                                                      max_depth=None,\n",
            "                                                      max_features='auto',\n",
            "                                                      max_leaf_nodes=None,\n",
            "                                                      max_samples=None,\n",
            "                                                      min_impurity_decrease=0.0,\n",
            "                                                      min_impurity_split=None,\n",
            "                                                      min_samples_leaf=1,\n",
            "                                                      min_samples_split=2,\n",
            "                                                      min_weight_fraction_leaf=0.0,\n",
            "                                                      n_estimators=100,\n",
            "                                                      n_jobs=None,\n",
            "                                                      oob_score=False,\n",
            "                                                      random_state=None,\n",
            "                                                      verbose=0,\n",
            "                                                      warm_start=False)],\n",
            "                   final_estimator=None, n_jobs=None, passthrough=False,\n",
            "                   stack_method='auto', verbose=0)\n",
            "CV Mean:  nan\n",
            "STD:  nan\n",
            "\n",
            "\n",
            "VotingClassifier(estimators=[AdaBoostClassifier(algorithm='SAMME.R',\n",
            "                                                base_estimator=None,\n",
            "                                                learning_rate=1.0,\n",
            "                                                n_estimators=50,\n",
            "                                                random_state=None),\n",
            "                             BaggingClassifier(base_estimator=None,\n",
            "                                               bootstrap=True,\n",
            "                                               bootstrap_features=False,\n",
            "                                               max_features=1.0,\n",
            "                                               max_samples=1.0, n_estimators=10,\n",
            "                                               n_jobs=None, oob_score=False,\n",
            "                                               random_state=None, verbose=0,\n",
            "                                               warm_start=False),\n",
            "                             Gradient...\n",
            "                                                    criterion='gini',\n",
            "                                                    max_depth=None,\n",
            "                                                    max_features='auto',\n",
            "                                                    max_leaf_nodes=None,\n",
            "                                                    max_samples=None,\n",
            "                                                    min_impurity_decrease=0.0,\n",
            "                                                    min_impurity_split=None,\n",
            "                                                    min_samples_leaf=1,\n",
            "                                                    min_samples_split=2,\n",
            "                                                    min_weight_fraction_leaf=0.0,\n",
            "                                                    n_estimators=100,\n",
            "                                                    n_jobs=None,\n",
            "                                                    oob_score=False,\n",
            "                                                    random_state=None,\n",
            "                                                    verbose=0,\n",
            "                                                    warm_start=False)],\n",
            "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
            "                 weights=None)\n",
            "CV Mean:  nan\n",
            "STD:  nan\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "AttributeError: 'AdaBoostClassifier' object has no attribute 'estimators_'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "AttributeError: 'AdaBoostClassifier' object has no attribute 'estimators_'\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVnlIi4Zv52a",
        "outputId": "a6a0db89-4f03-49be-dfe8-793839c3cea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "models = [obj1, obj2, obj3, obj4,obj5,obj6]\n",
        "for model in models:\n",
        "    print(model)\n",
        "    get_cv_scores(model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=50, random_state=None)\n",
            "CV Mean:  0.9416666666666668\n",
            "STD:  0.03118047822311616\n",
            "\n",
            "\n",
            "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
            "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
            "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
            "                  warm_start=False)\n",
            "CV Mean:  0.9583333333333334\n",
            "STD:  0.03118047822311617\n",
            "\n",
            "\n",
            "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "CV Mean:  0.9583333333333334\n",
            "STD:  0.03118047822311617\n",
            "\n",
            "\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "CV Mean:  0.9666666666666667\n",
            "STD:  0.03118047822311616\n",
            "\n",
            "\n",
            "StackingClassifier(cv=None,\n",
            "                   estimators=[AdaBoostClassifier(algorithm='SAMME.R',\n",
            "                                                  base_estimator=None,\n",
            "                                                  learning_rate=1.0,\n",
            "                                                  n_estimators=50,\n",
            "                                                  random_state=None),\n",
            "                               BaggingClassifier(base_estimator=None,\n",
            "                                                 bootstrap=True,\n",
            "                                                 bootstrap_features=False,\n",
            "                                                 max_features=1.0,\n",
            "                                                 max_samples=1.0,\n",
            "                                                 n_estimators=10, n_jobs=None,\n",
            "                                                 oob_score=False,\n",
            "                                                 random_state=None, verbose=0,\n",
            "                                                 warm_start=False...\n",
            "                                                      max_depth=None,\n",
            "                                                      max_features='auto',\n",
            "                                                      max_leaf_nodes=None,\n",
            "                                                      max_samples=None,\n",
            "                                                      min_impurity_decrease=0.0,\n",
            "                                                      min_impurity_split=None,\n",
            "                                                      min_samples_leaf=1,\n",
            "                                                      min_samples_split=2,\n",
            "                                                      min_weight_fraction_leaf=0.0,\n",
            "                                                      n_estimators=100,\n",
            "                                                      n_jobs=None,\n",
            "                                                      oob_score=False,\n",
            "                                                      random_state=None,\n",
            "                                                      verbose=0,\n",
            "                                                      warm_start=False)],\n",
            "                   final_estimator=None, n_jobs=None, passthrough=False,\n",
            "                   stack_method='auto', verbose=0)\n",
            "CV Mean:  nan\n",
            "STD:  nan\n",
            "\n",
            "\n",
            "VotingClassifier(estimators=[AdaBoostClassifier(algorithm='SAMME.R',\n",
            "                                                base_estimator=None,\n",
            "                                                learning_rate=1.0,\n",
            "                                                n_estimators=50,\n",
            "                                                random_state=None),\n",
            "                             BaggingClassifier(base_estimator=None,\n",
            "                                               bootstrap=True,\n",
            "                                               bootstrap_features=False,\n",
            "                                               max_features=1.0,\n",
            "                                               max_samples=1.0, n_estimators=10,\n",
            "                                               n_jobs=None, oob_score=False,\n",
            "                                               random_state=None, verbose=0,\n",
            "                                               warm_start=False),\n",
            "                             Gradient...\n",
            "                                                    criterion='gini',\n",
            "                                                    max_depth=None,\n",
            "                                                    max_features='auto',\n",
            "                                                    max_leaf_nodes=None,\n",
            "                                                    max_samples=None,\n",
            "                                                    min_impurity_decrease=0.0,\n",
            "                                                    min_impurity_split=None,\n",
            "                                                    min_samples_leaf=1,\n",
            "                                                    min_samples_split=2,\n",
            "                                                    min_weight_fraction_leaf=0.0,\n",
            "                                                    n_estimators=100,\n",
            "                                                    n_jobs=None,\n",
            "                                                    oob_score=False,\n",
            "                                                    random_state=None,\n",
            "                                                    verbose=0,\n",
            "                                                    warm_start=False)],\n",
            "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
            "                 weights=None)\n",
            "CV Mean:  nan\n",
            "STD:  nan\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "AttributeError: 'AdaBoostClassifier' object has no attribute 'estimators_'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "AttributeError: 'AdaBoostClassifier' object has no attribute 'estimators_'\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG8wPO1MwAsX"
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh2I1CNmv9vs",
        "outputId": "bf692996-56d0-4a61-f52a-b0026d93c223",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "logistic = linear_model.LogisticRegression(C=0.0001, class_weight={1:0.5, 0:0.5}, penalty='l2', solver='liblinear')\n",
        "get_cv_scores(logistic)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV Mean:  0.3416666666666666\n",
            "STD:  0.011785113019775776\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Y9zoT2v_n_",
        "outputId": "d15c36b0-f37d-40dd-b8f0-0b9e59034593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "logistic.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = logistic.predict(X_train)\n",
        "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_train))\n",
        "\n",
        "\n",
        "y_test_pred = logistic.predict(X_test)\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.34%\n",
            "Accuracy: 0.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7go_gyKwHFq"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXJqWWoFwJpR",
        "outputId": "4baaeaeb-c5b0-4d72-81db-051d68fba280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_estimator = [obj1, obj2, obj3, obj4, None]\n",
        "n_estimators = [40,50,60]\n",
        "learning_rate = [0.5,1,1.5]\n",
        "random_state = [1, None]\n",
        "\n",
        "param_grid = dict(base_estimator=base_estimator,n_estimators=n_estimators,learning_rate=learning_rate,random_state=random_state)\n",
        "\n",
        "\n",
        "grid = GridSearchCV(estimator=obj1, param_grid=param_grid, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print('Best Score: ', grid_result.best_score_)\n",
        "print('Best Params: ', grid_result.best_params_)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed:  4.3min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.975\n",
            "Best Params:  {'base_estimator': BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
            "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
            "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
            "                  warm_start=False), 'learning_rate': 0.5, 'n_estimators': 40, 'random_state': None}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:  4.6min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "438khoqhwN0q",
        "outputId": "ebe9db39-4b56-44d3-9e19-b126e9608b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_train_pred = grid.predict(X_train)\n",
        "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_train))\n",
        "\n",
        "\n",
        "y_test_pred = grid.predict(X_test)\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.00%\n",
            "Accuracy: 0.97%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}